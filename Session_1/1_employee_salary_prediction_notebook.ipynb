{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install seaborn library\n",
    "# !pip install seaborn\n",
    "# !pip install tensorflow\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjIiJdM4u1IE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the csv file \n",
    "salary_df = pd.read_csv('salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "q4_wPDKCu5Uc",
    "outputId": "886d2aaf-0205-4f46-96a7-629d0f367d2f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.9</td>\n",
       "      <td>56642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.2</td>\n",
       "      <td>54445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.2</td>\n",
       "      <td>64445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.7</td>\n",
       "      <td>57189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.9</td>\n",
       "      <td>63218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>55794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>56957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.1</td>\n",
       "      <td>57081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.5</td>\n",
       "      <td>61111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.9</td>\n",
       "      <td>67938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.1</td>\n",
       "      <td>66029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.3</td>\n",
       "      <td>83088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.9</td>\n",
       "      <td>81363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "      <td>93940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.8</td>\n",
       "      <td>91738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.1</td>\n",
       "      <td>98273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.9</td>\n",
       "      <td>101302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.2</td>\n",
       "      <td>113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.7</td>\n",
       "      <td>109431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.0</td>\n",
       "      <td>105582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.5</td>\n",
       "      <td>116969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.6</td>\n",
       "      <td>112635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.3</td>\n",
       "      <td>122391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.5</td>\n",
       "      <td>121872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.2</td>\n",
       "      <td>127345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.5</td>\n",
       "      <td>126756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.3</td>\n",
       "      <td>128765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.9</td>\n",
       "      <td>135675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.5</td>\n",
       "      <td>139465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YearsExperience  Salary\n",
       "0               1.1   39343\n",
       "1               1.3   46205\n",
       "2               1.5   37731\n",
       "3               2.0   43525\n",
       "4               2.2   39891\n",
       "5               2.9   56642\n",
       "6               3.0   60150\n",
       "7               3.2   54445\n",
       "8               3.2   64445\n",
       "9               3.7   57189\n",
       "10              3.9   63218\n",
       "11              4.0   55794\n",
       "12              4.0   56957\n",
       "13              4.1   57081\n",
       "14              4.5   61111\n",
       "15              4.9   67938\n",
       "16              5.1   66029\n",
       "17              5.3   83088\n",
       "18              5.9   81363\n",
       "19              6.0   93940\n",
       "20              6.8   91738\n",
       "21              7.1   98273\n",
       "22              7.9  101302\n",
       "23              8.2  113812\n",
       "24              8.7  109431\n",
       "25              9.0  105582\n",
       "26              9.5  116969\n",
       "27              9.6  112635\n",
       "28             10.3  122391\n",
       "29             10.5  121872\n",
       "30             11.2  127345\n",
       "31             11.5  126756\n",
       "32             12.3  128765\n",
       "33             12.9  135675\n",
       "34             13.5  139465"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMcr7xqMQre2"
   },
   "source": [
    "# PERFORM EXPLORATORY DATA ANALYSIS AND VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f01de0bda50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any Null values\n",
    "sns.heatmap(salary_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "hMq3-KWOx0e1",
    "outputId": "22a5b184-1f07-46ef-dfc1-f8377fd7042f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   YearsExperience  35 non-null     float64\n",
      " 1   Salary           35 non-null     int64  \n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 688.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Check the dataframe info\n",
    "\n",
    "salary_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Nn1Oxk2SzPX3",
    "outputId": "95f0265a-5e75-4a32-d771-4b3d15850c3c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.308571</td>\n",
       "      <td>83945.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.618610</td>\n",
       "      <td>32162.673003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>37731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.450000</td>\n",
       "      <td>57019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.300000</td>\n",
       "      <td>81363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.250000</td>\n",
       "      <td>113223.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.500000</td>\n",
       "      <td>139465.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       YearsExperience         Salary\n",
       "count        35.000000      35.000000\n",
       "mean          6.308571   83945.600000\n",
       "std           3.618610   32162.673003\n",
       "min           1.100000   37731.000000\n",
       "25%           3.450000   57019.000000\n",
       "50%           5.300000   81363.000000\n",
       "75%           9.250000  113223.500000\n",
       "max          13.500000  139465.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical summary of the dataframe\n",
    "\n",
    "salary_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f01dbc50b50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f01dbca16d0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df.hist(bins = 30, figsize = (20,10), color = 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53qDZFRn3-S1"
   },
   "source": [
    "# CREATE TRAINING AND TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OXZB2F21e4H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = salary_df[['YearsExperience']]\n",
    "y = salary_df[['Salary']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YearsExperience\n",
       "0               1.1\n",
       "1               1.3\n",
       "2               1.5\n",
       "3               2.0\n",
       "4               2.2\n",
       "5               2.9\n",
       "6               3.0\n",
       "7               3.2\n",
       "8               3.2\n",
       "9               3.7\n",
       "10              3.9\n",
       "11              4.0\n",
       "12              4.0\n",
       "13              4.1\n",
       "14              4.5\n",
       "15              4.9\n",
       "16              5.1\n",
       "17              5.3\n",
       "18              5.9\n",
       "19              6.0\n",
       "20              6.8\n",
       "21              7.1\n",
       "22              7.9\n",
       "23              8.2\n",
       "24              8.7\n",
       "25              9.0\n",
       "26              9.5\n",
       "27              9.6\n",
       "28             10.3\n",
       "29             10.5\n",
       "30             11.2\n",
       "31             11.5\n",
       "32             12.3\n",
       "33             12.9\n",
       "34             13.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>61111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>67938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>66029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>83088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>91738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>98273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>101302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>109431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>105582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>116969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>112635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>122391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>121872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>127345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>126756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>128765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>135675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>139465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary\n",
       "0    39343\n",
       "1    46205\n",
       "2    37731\n",
       "3    43525\n",
       "4    39891\n",
       "5    56642\n",
       "6    60150\n",
       "7    54445\n",
       "8    64445\n",
       "9    57189\n",
       "10   63218\n",
       "11   55794\n",
       "12   56957\n",
       "13   57081\n",
       "14   61111\n",
       "15   67938\n",
       "16   66029\n",
       "17   83088\n",
       "18   81363\n",
       "19   93940\n",
       "20   91738\n",
       "21   98273\n",
       "22  101302\n",
       "23  113812\n",
       "24  109431\n",
       "25  105582\n",
       "26  116969\n",
       "27  112635\n",
       "28  122391\n",
       "29  121872\n",
       "30  127345\n",
       "31  126756\n",
       "32  128765\n",
       "33  135675\n",
       "34  139465"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XpGU63Ne1e9P",
    "outputId": "e16c74ca-dc1c-416c-dc44-7f927bb99bc6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OjGj0RALA0qZ",
    "outputId": "26559a6c-880b-45b4-a1e8-3c4b92bea889",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIeiK1maA6mm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1],\n",
       "       [ 1.3],\n",
       "       [ 1.5],\n",
       "       [ 2. ],\n",
       "       [ 2.2],\n",
       "       [ 2.9],\n",
       "       [ 3. ],\n",
       "       [ 3.2],\n",
       "       [ 3.2],\n",
       "       [ 3.7],\n",
       "       [ 3.9],\n",
       "       [ 4. ],\n",
       "       [ 4. ],\n",
       "       [ 4.1],\n",
       "       [ 4.5],\n",
       "       [ 4.9],\n",
       "       [ 5.1],\n",
       "       [ 5.3],\n",
       "       [ 5.9],\n",
       "       [ 6. ],\n",
       "       [ 6.8],\n",
       "       [ 7.1],\n",
       "       [ 7.9],\n",
       "       [ 8.2],\n",
       "       [ 8.7],\n",
       "       [ 9. ],\n",
       "       [ 9.5],\n",
       "       [ 9.6],\n",
       "       [10.3],\n",
       "       [10.5],\n",
       "       [11.2],\n",
       "       [11.5],\n",
       "       [12.3],\n",
       "       [12.9],\n",
       "       [13.5]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only take the numerical variables and scale them\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoReLFfnA6uF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idWHLv5alF4C"
   },
   "source": [
    "# Train a Linear regresssion model using SKLearn (Note: SageMaker SDK / APIs are not used yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yHL-6mKwBURs",
    "outputId": "10d71b6d-9c2b-4bab-8b27-d3c5883e6a25",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "regresssion_model_sklearn = LinearRegression(fit_intercept = True)\n",
    "regresssion_model_sklearn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "elD8m5N0BgEY",
    "outputId": "16a1813d-a0f1-4d1f-dc02-d7ad5a445417",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005891613075591"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresssion_model_sklearn_accuracy = regresssion_model_sklearn.score(X_test, y_test)\n",
    "regresssion_model_sklearn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model Coefficient (m):  [[8608.755]]\n",
      "Linear Model Coefficient (b):  [29311.54]\n"
     ]
    }
   ],
   "source": [
    "print('Linear Model Coefficient (m): ', regresssion_model_sklearn.coef_)\n",
    "print('Linear Model Coefficient (b): ', regresssion_model_sklearn.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Trained Model's performance (Note: SageMaker SDK/APIs are not used yet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict = regresssion_model_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55137.805],\n",
       "       [63746.56 ],\n",
       "       [63746.56 ],\n",
       "       [90433.7  ],\n",
       "       [54276.93 ],\n",
       "       [46529.047],\n",
       "       [99903.33 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Salary vs. Years of Experience')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(X_train, y_train, color = 'gray')\n",
    "plt.plot(X_train, regresssion_model_sklearn.predict(X_train), color = 'red')\n",
    "plt.ylabel('Salary')\n",
    "plt.xlabel('Number of Years of Experience')\n",
    "plt.title('Salary vs. Years of Experience')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN A LINEAR LEARNER MODEL USING SAGEMAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::667787699598:role/service-role/AmazonSageMaker-ExecutionRole-20221202T091553\n"
     ]
    }
   ],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = Session().default_bucket()\n",
    "\n",
    "# Let's define the S3 bucket and prefix that we want to use in this session\n",
    "bucket = 'gf-sagemaker-practice-1' # bucket named 'sagemaker-practical' was created beforehand\n",
    "prefix = 'linear_learner' # prefix is the subfolder within the bucket.\n",
    "\n",
    "# Let's get the execution role for the notebook instance. \n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d64e893b211e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "y_train = y_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io # The io module allows for dealing with various types of I/O (text I/O, binary I/O and raw I/O). \n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac # sagemaker common libary\n",
    "\n",
    "# Code below converts the data in numpy array format to RecordIO format\n",
    "# This is the format required by Sagemaker Linear Learner \n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it, hence we need to reset to zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://gf-sagemaker-practice-1/linear_learner/train/linear-train-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Code to upload RecordIO data to S3\n",
    " \n",
    "# Key refers to the name of the file    \n",
    "key = 'linear-train-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the training data location in s3\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure that the target label is a vector\n",
    "y_test = y_test[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to upload RecordIO data to S3\n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_test, y_test)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it\n",
    "# Let's reset that back to zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://gf-sagemaker-practice-1/linear_learner/test/linear-test-data\n"
     ]
    }
   ],
   "source": [
    "# Key refers to the name of the file    \n",
    "key = 'linear-test-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the testing data location in s3\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded to: s3://gf-sagemaker-practice-1/linear_learner/output\n"
     ]
    }
   ],
   "source": [
    "# create an output placeholder in S3 bucket to store the linear learner output\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# This code is used to get the training container of sagemaker built-in algorithms\n",
    "# all we have to do is to specify the name of the algorithm, that we want to use\n",
    "\n",
    "# Let's obtain a reference to the linearLearner container image\n",
    "# Note that all regression models are named estimators\n",
    "# You don't have to specify (hardcode) the region, get_image_uri will get the current region name using boto3.Session\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-02 02:57:02 Starting - Starting the training job...\n",
      "2022-12-02 02:57:31 Starting - Preparing the instances for trainingProfilerReport-1669949821: InProgress\n",
      "......\n",
      "2022-12-02 02:58:31 Downloading - Downloading input data...\n",
      "2022-12-02 02:58:51 Training - Downloading the training image.........\n",
      "2022-12-02 03:00:27 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:30 INFO 140178018830144] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:30 INFO 140178018830144] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '5', 'feature_dim': '1', 'loss': 'absolute_loss', 'mini_batch_size': '5', 'num_models': '2', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:30 INFO 140178018830144] Final configuration: {'mini_batch_size': '5', 'epochs': '5', 'feature_dim': '1', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '2', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 WARNING 140178018830144] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Final configuration: {'mini_batch_size': '5', 'epochs': '5', 'feature_dim': '1', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '2', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 WARNING 140178018830144] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Using default worker.\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.540] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 14, \"num_examples\": 1, \"num_bytes\": 240}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Create Store: local\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.704] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 163, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f7d332a6110>\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Scaling model computed with parameters:\n",
      " {'stdev_label': \u001b[0m\n",
      "\u001b[34m[33271.125]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[3.8381953]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[85412.4]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[6.616]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.75063, \"EndTime\": 1669950034.7506638, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 33.0, \"count\": 1, \"min\": 33, \"max\": 33}, \"Total Batches Seen\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Max Records Seen Between Resets\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Batches Seen Between Resets\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.845] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 94, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8453689, \"EndTime\": 1669950034.8454144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8915736579895019, \"count\": 1, \"min\": 0.8915736579895019, \"max\": 0.8915736579895019}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8454916, \"EndTime\": 1669950034.8455052, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8860842895507812, \"count\": 1, \"min\": 0.8860842895507812, \"max\": 0.8860842895507812}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, epoch=0, train absolute_loss_objective <loss>=0.8915736579895019\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=absolute_loss_objective, value=0.8860842895507812\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saved checkpoint to \"/tmp/tmp3k7fo4pa/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.7509162, \"EndTime\": 1669950034.858432, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 61.0, \"count\": 1, \"min\": 61, \"max\": 61}, \"Total Batches Seen\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Max Records Seen Between Resets\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Batches Seen Between Resets\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Batches Since Last Reset\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #throughput_metric: host=algo-1, train throughput=260.1280079384768 records/second\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.868] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 9, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8684697, \"EndTime\": 1669950034.8685076, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8640338993072509, \"count\": 1, \"min\": 0.8640338993072509, \"max\": 0.8640338993072509}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8685787, \"EndTime\": 1669950034.8685987, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8588056182861328, \"count\": 1, \"min\": 0.8588056182861328, \"max\": 0.8588056182861328}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, epoch=1, train absolute_loss_objective <loss>=0.8640338993072509\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=absolute_loss_objective, value=0.8588056182861328\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saved checkpoint to \"/tmp/tmp3iozdwcb/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8587363, \"EndTime\": 1669950034.8751876, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 89.0, \"count\": 1, \"min\": 89, \"max\": 89}, \"Total Batches Seen\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Max Records Seen Between Resets\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Batches Seen Between Resets\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Batches Since Last Reset\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #throughput_metric: host=algo-1, train throughput=1687.945728412096 records/second\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.886] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 10, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8861248, \"EndTime\": 1669950034.8861606, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8431740760803222, \"count\": 1, \"min\": 0.8431740760803222, \"max\": 0.8431740760803222}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8862844, \"EndTime\": 1669950034.8863056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8378548049926757, \"count\": 1, \"min\": 0.8378548049926757, \"max\": 0.8378548049926757}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, epoch=2, train absolute_loss_objective <loss>=0.8431740760803222\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=absolute_loss_objective, value=0.8378548049926757\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saved checkpoint to \"/tmp/tmp4b8ohho_/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.8754756, \"EndTime\": 1669950034.892933, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 117.0, \"count\": 1, \"min\": 117, \"max\": 117}, \"Total Batches Seen\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Max Records Seen Between Resets\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Batches Seen Between Resets\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Batches Since Last Reset\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #throughput_metric: host=algo-1, train throughput=1584.6783430036432 records/second\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.905] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 11, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.905285, \"EndTime\": 1669950034.9053233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.822093391418457, \"count\": 1, \"min\": 0.822093391418457, \"max\": 0.822093391418457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.90549, \"EndTime\": 1669950034.9055903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8165612411499024, \"count\": 1, \"min\": 0.8165612411499024, \"max\": 0.8165612411499024}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, epoch=3, train absolute_loss_objective <loss>=0.822093391418457\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=absolute_loss_objective, value=0.8165612411499024\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saved checkpoint to \"/tmp/tmp_mjko2ar/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.893384, \"EndTime\": 1669950034.912441, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 145.0, \"count\": 1, \"min\": 145, \"max\": 145}, \"Total Batches Seen\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Max Records Seen Between Resets\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Batches Seen Between Resets\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Batches Since Last Reset\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #throughput_metric: host=algo-1, train throughput=1458.5984400616026 records/second\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.923] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 10, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.9232635, \"EndTime\": 1669950034.923302, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8008684730529785, \"count\": 1, \"min\": 0.8008684730529785, \"max\": 0.8008684730529785}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.9233725, \"EndTime\": 1669950034.923392, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7950147533416748, \"count\": 1, \"min\": 0.7950147533416748, \"max\": 0.7950147533416748}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, epoch=4, train absolute_loss_objective <loss>=0.8008684730529785\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=absolute_loss_objective, value=0.7950147533416748\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saved checkpoint to \"/tmp/tmp4wgmxi6q/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.9127152, \"EndTime\": 1669950034.9296763, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 173.0, \"count\": 1, \"min\": 173, \"max\": 173}, \"Total Batches Seen\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Max Records Seen Between Resets\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Max Batches Seen Between Resets\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Batches Since Last Reset\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}}}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #throughput_metric: host=algo-1, train throughput=1640.643066692744 records/second\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 WARNING 140178018830144] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 WARNING 140178018830144] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.930] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 0, \"num_examples\": 1, \"num_bytes\": 240}\u001b[0m\n",
      "\u001b[34m[2022-12-02 03:00:34.942] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 9, \"num_examples\": 6, \"num_bytes\": 1344}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #train_score (algo-1) : ('absolute_loss_objective', 25930.783203125)\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #train_score (algo-1) : ('mse', 850566304.0)\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #train_score (algo-1) : ('absolute_loss', 25930.783203125)\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #train_score (algo-1) : ('rmse', 29164.469890604905)\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #train_score (algo-1) : ('r2', 0.1852864678045063)\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #train_score (algo-1) : ('mae', 25930.783203125)\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, train absolute_loss_objective <loss>=25930.783203125\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, train mse <loss>=850566304.0\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, train absolute_loss <loss>=25930.783203125\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, train rmse <loss>=29164.469890604905\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, train r2 <loss>=0.1852864678045063\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] #quality_metric: host=algo-1, train mae <loss>=25930.783203125\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Saved checkpoint to \"/tmp/tmpo49u2c_p/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[12/02/2022 03:00:34 INFO 140178018830144] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1669950034.5258703, \"EndTime\": 1669950034.9489186, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 223.88625144958496, \"count\": 1, \"min\": 223.88625144958496, \"max\": 223.88625144958496}, \"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"check_early_stopping.time\": {\"sum\": 5.3462982177734375, \"count\": 5, \"min\": 0.9136199951171875, \"max\": 1.2404918670654297}, \"update.time\": {\"sum\": 159.09266471862793, \"count\": 5, \"min\": 13.880252838134766, \"max\": 99.47729110717773}, \"finalize.time\": {\"sum\": 16.205549240112305, \"count\": 1, \"min\": 16.205549240112305, \"max\": 16.205549240112305}, \"setuptime\": {\"sum\": 3.450632095336914, \"count\": 1, \"min\": 3.450632095336914, \"max\": 3.450632095336914}, \"totaltime\": {\"sum\": 618.2780265808105, \"count\": 1, \"min\": 618.2780265808105, \"max\": 618.2780265808105}}}\u001b[0m\n",
      "\n",
      "2022-12-02 03:00:59 Uploading - Uploading generated training model\n",
      "2022-12-02 03:00:59 Completed - Training job completed\n",
      "Training seconds: 147\n",
      "Billable seconds: 147\n"
     ]
    }
   ],
   "source": [
    "# We have pass in the container, the type of instance that we would like to use for training \n",
    "# output path and sagemaker session into the Estimator. \n",
    "# We can also specify how many instances we would like to use for training\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count = 1, \n",
    "                                       train_instance_type = 'ml.c4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 5,\n",
    "                           num_models = 2,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOY AND TEST THE TRAINED LINEAR LEARNER MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# Deploying the model to perform inference \n",
    "\n",
    "linear_regressor = linear.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "# Content type overrides the data that will be passed to the deployed model, since the deployed model expects data in text/csv format.\n",
    "\n",
    "# Serializer accepts a single argument, the input data, and returns a sequence of bytes in the specified content type\n",
    "\n",
    "# Deserializer accepts two arguments, the result data and the response content type, and return a sequence of bytes in the specified content type.\n",
    "\n",
    "# Reference: https://sagemaker.readthedocs.io/en/stable/predictors.html\n",
    "\n",
    "# linear_regressor.content_type = 'text/csv'\n",
    "linear_regressor.serializer = csv_serializer\n",
    "linear_regressor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# making prediction on the test data\n",
    "\n",
    "result = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 75469.203125},\n",
       "  {'score': 76624.421875},\n",
       "  {'score': 76624.421875},\n",
       "  {'score': 80205.578125},\n",
       "  {'score': 75353.6875},\n",
       "  {'score': 74313.9921875},\n",
       "  {'score': 81476.3046875}]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result # results are in Json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since the result is in json format, we access the scores by iterating through the scores in the predictions\n",
    "\n",
    "predictions = np.array([r['score'] for r in result['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75469.203125 , 76624.421875 , 76624.421875 , 80205.578125 ,\n",
       "       75353.6875   , 74313.9921875, 81476.3046875])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Salary vs. Years of Experience')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VISUALIZE TEST SET RESULTS\n",
    "plt.scatter(X_test, y_test, color = 'gray')\n",
    "plt.plot(X_test, predictions, color = 'red')\n",
    "plt.xlabel('Years of Experience (Testing Dataset)')\n",
    "plt.ylabel('salary')\n",
    "plt.title('Salary vs. Years of Experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "\n",
    "linear_regressor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graduate_Admission_Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
